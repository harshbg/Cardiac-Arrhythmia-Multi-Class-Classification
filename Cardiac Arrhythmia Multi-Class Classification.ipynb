{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardiac Arrhythmia Multy-Class Classification \n",
    "\n",
    "Analyze data and address missing data if there is any. \n",
    "\n",
    "Decide aboute a good evaluation strategy and justify your choice. \n",
    "\n",
    "Find the best parameters for the following classification models: \n",
    "- KNN classifcation \n",
    "- Logistic Regression\n",
    "- Linear Supprt Vector Machine\n",
    "- Kerenilzed Support Vector Machine\n",
    "- Decision Tree\n",
    "- Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Reading\n",
    "Starting with reading the data file and creating a dataframe for putting the output of all the models that \n",
    " we will be running. The purpose of doing this is it will be easy for us to compare the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>QRS_duration</th>\n",
       "      <th>P-R_interval</th>\n",
       "      <th>Q-T_interval</th>\n",
       "      <th>T_interval</th>\n",
       "      <th>P_interval</th>\n",
       "      <th>QRS</th>\n",
       "      <th>...</th>\n",
       "      <th>V6_Amp_Q</th>\n",
       "      <th>V6_Amp_R</th>\n",
       "      <th>V6_Amp_S</th>\n",
       "      <th>V6_Amp_R'</th>\n",
       "      <th>V6_Amp_S'</th>\n",
       "      <th>V6_Amp_P</th>\n",
       "      <th>V6_Amp_T</th>\n",
       "      <th>V6_QRSA</th>\n",
       "      <th>V6_QRSTA</th>\n",
       "      <th>cardiac_arrhythmia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.0</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "      <td>452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.471239</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>166.188053</td>\n",
       "      <td>68.170354</td>\n",
       "      <td>88.920354</td>\n",
       "      <td>155.152655</td>\n",
       "      <td>367.207965</td>\n",
       "      <td>169.949115</td>\n",
       "      <td>90.004425</td>\n",
       "      <td>33.676991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278982</td>\n",
       "      <td>9.048009</td>\n",
       "      <td>-1.457301</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514823</td>\n",
       "      <td>1.222345</td>\n",
       "      <td>19.326106</td>\n",
       "      <td>29.473230</td>\n",
       "      <td>3.880531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.466631</td>\n",
       "      <td>0.497955</td>\n",
       "      <td>37.170340</td>\n",
       "      <td>16.590803</td>\n",
       "      <td>15.364394</td>\n",
       "      <td>44.842283</td>\n",
       "      <td>33.385421</td>\n",
       "      <td>35.633072</td>\n",
       "      <td>25.826643</td>\n",
       "      <td>45.431434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548876</td>\n",
       "      <td>3.472862</td>\n",
       "      <td>2.002430</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347531</td>\n",
       "      <td>1.426052</td>\n",
       "      <td>13.503922</td>\n",
       "      <td>18.493927</td>\n",
       "      <td>4.407097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-44.200000</td>\n",
       "      <td>-38.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>17.550000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>25.825000</td>\n",
       "      <td>41.125000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>88.800000</td>\n",
       "      <td>115.900000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         Sex      Height      Weight  QRS_duration  \\\n",
       "count  452.000000  452.000000  452.000000  452.000000    452.000000   \n",
       "mean    46.471239    0.550885  166.188053   68.170354     88.920354   \n",
       "std     16.466631    0.497955   37.170340   16.590803     15.364394   \n",
       "min      0.000000    0.000000  105.000000    6.000000     55.000000   \n",
       "25%     36.000000    0.000000  160.000000   59.000000     80.000000   \n",
       "50%     47.000000    1.000000  164.000000   68.000000     86.000000   \n",
       "75%     58.000000    1.000000  170.000000   79.000000     94.000000   \n",
       "max     83.000000    1.000000  780.000000  176.000000    188.000000   \n",
       "\n",
       "       P-R_interval  Q-T_interval  T_interval  P_interval         QRS  \\\n",
       "count    452.000000    452.000000  452.000000  452.000000  452.000000   \n",
       "mean     155.152655    367.207965  169.949115   90.004425   33.676991   \n",
       "std       44.842283     33.385421   35.633072   25.826643   45.431434   \n",
       "min        0.000000    232.000000  108.000000    0.000000 -172.000000   \n",
       "25%      142.000000    350.000000  148.000000   79.000000    3.750000   \n",
       "50%      157.000000    367.000000  162.000000   91.000000   40.000000   \n",
       "75%      175.000000    384.000000  179.000000  102.000000   66.000000   \n",
       "max      524.000000    509.000000  381.000000  205.000000  169.000000   \n",
       "\n",
       "              ...            V6_Amp_Q    V6_Amp_R    V6_Amp_S   V6_Amp_R'  \\\n",
       "count         ...          452.000000  452.000000  452.000000  452.000000   \n",
       "mean          ...           -0.278982    9.048009   -1.457301    0.003982   \n",
       "std           ...            0.548876    3.472862    2.002430    0.050118   \n",
       "min           ...           -4.100000    0.000000  -28.600000    0.000000   \n",
       "25%           ...           -0.425000    6.600000   -2.100000    0.000000   \n",
       "50%           ...            0.000000    8.800000   -1.100000    0.000000   \n",
       "75%           ...            0.000000   11.200000    0.000000    0.000000   \n",
       "max           ...            0.000000   23.600000    0.000000    0.800000   \n",
       "\n",
       "       V6_Amp_S'    V6_Amp_P    V6_Amp_T     V6_QRSA    V6_QRSTA  \\\n",
       "count      452.0  452.000000  452.000000  452.000000  452.000000   \n",
       "mean         0.0    0.514823    1.222345   19.326106   29.473230   \n",
       "std          0.0    0.347531    1.426052   13.503922   18.493927   \n",
       "min          0.0   -0.800000   -6.000000  -44.200000  -38.600000   \n",
       "25%          0.0    0.400000    0.500000   11.450000   17.550000   \n",
       "50%          0.0    0.500000    1.350000   18.100000   27.900000   \n",
       "75%          0.0    0.700000    2.100000   25.825000   41.125000   \n",
       "max          0.0    2.400000    6.000000   88.800000  115.900000   \n",
       "\n",
       "       cardiac_arrhythmia  \n",
       "count          452.000000  \n",
       "mean             3.880531  \n",
       "std              4.407097  \n",
       "min              1.000000  \n",
       "25%              1.000000  \n",
       "50%              1.000000  \n",
       "75%              6.000000  \n",
       "max             16.000000  \n",
       "\n",
       "[8 rows x 275 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv('cardiac_arrhythmia1.csv')\n",
    "output = pd.DataFrame(index=None, columns=['model','train_Rsquare', 'test_Rsquare', 'train_MSE','test_MSE'])\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling the missing value\n",
    "While going through the dataset we observed that out of 279 columns 5 columns have missing value in the form of '?'.\n",
    "The approach which we will following is, first replacing '?' with numpy NAN and then imputing the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['J'] = data['J'].replace('?',np.NaN)\n",
    "data['Heart_Rate'] = data['Heart_Rate'].replace('?',np.NaN)\n",
    "data['P'] = data['P'].replace('?',np.NaN)\n",
    "data['T'] = data['T'].replace('?',np.NaN)\n",
    "data['QRST'] = data['QRST'].replace('?',np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting the dataset\n",
    "Segregating the whole dataset into X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Y = data.cardiac_arrhythmia.values.ravel()\n",
    "Data_X=data.drop('cardiac_arrhythmia', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 14, 15, 16], dtype=int64),\n",
       " array([245,  44,  15,  15,  13,  25,   3,   2,   9,  50,   4,   5,  22],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Data_Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop column\n",
    "We can observe that column J have a lot of missing value. It will not be a good practice to impute mean values in this column.\n",
    "Better option will be that we drop this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>QRS_duration</th>\n",
       "      <th>P-R_interval</th>\n",
       "      <th>Q-T_interval</th>\n",
       "      <th>T_interval</th>\n",
       "      <th>P_interval</th>\n",
       "      <th>QRS</th>\n",
       "      <th>...</th>\n",
       "      <th>V6_Amp_JJ</th>\n",
       "      <th>V6_Amp_Q</th>\n",
       "      <th>V6_Amp_R</th>\n",
       "      <th>V6_Amp_S</th>\n",
       "      <th>V6_Amp_R'</th>\n",
       "      <th>V6_Amp_S'</th>\n",
       "      <th>V6_Amp_P</th>\n",
       "      <th>V6_Amp_T</th>\n",
       "      <th>V6_QRSA</th>\n",
       "      <th>V6_QRSTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>51</td>\n",
       "      <td>100</td>\n",
       "      <td>167</td>\n",
       "      <td>321</td>\n",
       "      <td>174</td>\n",
       "      <td>91</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>52</td>\n",
       "      <td>77</td>\n",
       "      <td>129</td>\n",
       "      <td>377</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>157</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.8</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>56</td>\n",
       "      <td>84</td>\n",
       "      <td>118</td>\n",
       "      <td>354</td>\n",
       "      <td>160</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>30.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>67</td>\n",
       "      <td>89</td>\n",
       "      <td>130</td>\n",
       "      <td>383</td>\n",
       "      <td>156</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.1</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>72</td>\n",
       "      <td>102</td>\n",
       "      <td>135</td>\n",
       "      <td>401</td>\n",
       "      <td>156</td>\n",
       "      <td>83</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>12.3</td>\n",
       "      <td>19.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>143</td>\n",
       "      <td>373</td>\n",
       "      <td>150</td>\n",
       "      <td>65</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>58</td>\n",
       "      <td>78</td>\n",
       "      <td>155</td>\n",
       "      <td>382</td>\n",
       "      <td>163</td>\n",
       "      <td>81</td>\n",
       "      <td>-24</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>73</td>\n",
       "      <td>91</td>\n",
       "      <td>180</td>\n",
       "      <td>355</td>\n",
       "      <td>157</td>\n",
       "      <td>104</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>48.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>158</td>\n",
       "      <td>399</td>\n",
       "      <td>163</td>\n",
       "      <td>94</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>39.2</td>\n",
       "      <td>54.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>132</td>\n",
       "      <td>350</td>\n",
       "      <td>169</td>\n",
       "      <td>65</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>17.2</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>59</td>\n",
       "      <td>82</td>\n",
       "      <td>145</td>\n",
       "      <td>347</td>\n",
       "      <td>169</td>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>19.5</td>\n",
       "      <td>41.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>353</td>\n",
       "      <td>122</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>63</td>\n",
       "      <td>91</td>\n",
       "      <td>154</td>\n",
       "      <td>392</td>\n",
       "      <td>175</td>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>181</td>\n",
       "      <td>399</td>\n",
       "      <td>158</td>\n",
       "      <td>79</td>\n",
       "      <td>-12</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>58</td>\n",
       "      <td>83</td>\n",
       "      <td>251</td>\n",
       "      <td>383</td>\n",
       "      <td>189</td>\n",
       "      <td>183</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>9.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>17.1</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>67</td>\n",
       "      <td>90</td>\n",
       "      <td>122</td>\n",
       "      <td>336</td>\n",
       "      <td>177</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>132</td>\n",
       "      <td>364</td>\n",
       "      <td>169</td>\n",
       "      <td>82</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>19.7</td>\n",
       "      <td>34.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>59</td>\n",
       "      <td>75</td>\n",
       "      <td>157</td>\n",
       "      <td>406</td>\n",
       "      <td>143</td>\n",
       "      <td>92</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>18.4</td>\n",
       "      <td>28.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>55</td>\n",
       "      <td>82</td>\n",
       "      <td>140</td>\n",
       "      <td>388</td>\n",
       "      <td>149</td>\n",
       "      <td>82</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>35.3</td>\n",
       "      <td>57.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>80</td>\n",
       "      <td>109</td>\n",
       "      <td>128</td>\n",
       "      <td>382</td>\n",
       "      <td>195</td>\n",
       "      <td>60</td>\n",
       "      <td>-34</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>73</td>\n",
       "      <td>94</td>\n",
       "      <td>186</td>\n",
       "      <td>373</td>\n",
       "      <td>224</td>\n",
       "      <td>125</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>44.0</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>54</td>\n",
       "      <td>95</td>\n",
       "      <td>161</td>\n",
       "      <td>407</td>\n",
       "      <td>168</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>65</td>\n",
       "      <td>90</td>\n",
       "      <td>164</td>\n",
       "      <td>420</td>\n",
       "      <td>381</td>\n",
       "      <td>99</td>\n",
       "      <td>-8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>17.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>83</td>\n",
       "      <td>96</td>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "      <td>301</td>\n",
       "      <td>82</td>\n",
       "      <td>-37</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>57</td>\n",
       "      <td>83</td>\n",
       "      <td>164</td>\n",
       "      <td>359</td>\n",
       "      <td>154</td>\n",
       "      <td>69</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>56.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>203</td>\n",
       "      <td>367</td>\n",
       "      <td>171</td>\n",
       "      <td>106</td>\n",
       "      <td>-7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>21</td>\n",
       "      <td>140</td>\n",
       "      <td>157</td>\n",
       "      <td>438</td>\n",
       "      <td>226</td>\n",
       "      <td>81</td>\n",
       "      <td>-40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>36.7</td>\n",
       "      <td>115.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>93</td>\n",
       "      <td>87</td>\n",
       "      <td>150</td>\n",
       "      <td>362</td>\n",
       "      <td>177</td>\n",
       "      <td>96</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>52.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>163</td>\n",
       "      <td>340</td>\n",
       "      <td>162</td>\n",
       "      <td>102</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>20.9</td>\n",
       "      <td>40.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>65</td>\n",
       "      <td>133</td>\n",
       "      <td>148</td>\n",
       "      <td>417</td>\n",
       "      <td>260</td>\n",
       "      <td>92</td>\n",
       "      <td>-158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>63</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>23.7</td>\n",
       "      <td>26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>24</td>\n",
       "      <td>77</td>\n",
       "      <td>125</td>\n",
       "      <td>358</td>\n",
       "      <td>159</td>\n",
       "      <td>70</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>49.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>29</td>\n",
       "      <td>123</td>\n",
       "      <td>145</td>\n",
       "      <td>361</td>\n",
       "      <td>221</td>\n",
       "      <td>80</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>19.6</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>25.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>56</td>\n",
       "      <td>79</td>\n",
       "      <td>145</td>\n",
       "      <td>381</td>\n",
       "      <td>173</td>\n",
       "      <td>101</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>42</td>\n",
       "      <td>88</td>\n",
       "      <td>123</td>\n",
       "      <td>362</td>\n",
       "      <td>228</td>\n",
       "      <td>81</td>\n",
       "      <td>-18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>15.1</td>\n",
       "      <td>84.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>149</td>\n",
       "      <td>290</td>\n",
       "      <td>128</td>\n",
       "      <td>93</td>\n",
       "      <td>-67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>-8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>65</td>\n",
       "      <td>88</td>\n",
       "      <td>155</td>\n",
       "      <td>360</td>\n",
       "      <td>163</td>\n",
       "      <td>71</td>\n",
       "      <td>-22</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>62</td>\n",
       "      <td>79</td>\n",
       "      <td>155</td>\n",
       "      <td>367</td>\n",
       "      <td>153</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>24.1</td>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>144</td>\n",
       "      <td>340</td>\n",
       "      <td>148</td>\n",
       "      <td>82</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>36.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>63</td>\n",
       "      <td>87</td>\n",
       "      <td>142</td>\n",
       "      <td>391</td>\n",
       "      <td>137</td>\n",
       "      <td>88</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "      <td>146</td>\n",
       "      <td>357</td>\n",
       "      <td>179</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>30.1</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>170</td>\n",
       "      <td>383</td>\n",
       "      <td>152</td>\n",
       "      <td>115</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>33.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>72</td>\n",
       "      <td>88</td>\n",
       "      <td>153</td>\n",
       "      <td>389</td>\n",
       "      <td>172</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>24.9</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>74</td>\n",
       "      <td>143</td>\n",
       "      <td>374</td>\n",
       "      <td>146</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>40.1</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>85</td>\n",
       "      <td>143</td>\n",
       "      <td>363</td>\n",
       "      <td>146</td>\n",
       "      <td>84</td>\n",
       "      <td>-40</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>75</td>\n",
       "      <td>88</td>\n",
       "      <td>157</td>\n",
       "      <td>384</td>\n",
       "      <td>132</td>\n",
       "      <td>112</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>63</td>\n",
       "      <td>81</td>\n",
       "      <td>143</td>\n",
       "      <td>325</td>\n",
       "      <td>218</td>\n",
       "      <td>74</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>37.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>75</td>\n",
       "      <td>91</td>\n",
       "      <td>134</td>\n",
       "      <td>376</td>\n",
       "      <td>160</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>57</td>\n",
       "      <td>81</td>\n",
       "      <td>151</td>\n",
       "      <td>363</td>\n",
       "      <td>166</td>\n",
       "      <td>80</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>39.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>199</td>\n",
       "      <td>382</td>\n",
       "      <td>154</td>\n",
       "      <td>117</td>\n",
       "      <td>-37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>137</td>\n",
       "      <td>361</td>\n",
       "      <td>201</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>38.0</td>\n",
       "      <td>62.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>68</td>\n",
       "      <td>108</td>\n",
       "      <td>176</td>\n",
       "      <td>365</td>\n",
       "      <td>194</td>\n",
       "      <td>116</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>-28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-44.2</td>\n",
       "      <td>-33.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>106</td>\n",
       "      <td>386</td>\n",
       "      <td>218</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>127</td>\n",
       "      <td>364</td>\n",
       "      <td>138</td>\n",
       "      <td>78</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>452 rows Ã— 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  Height  Weight  QRS_duration  P-R_interval  Q-T_interval  \\\n",
       "0     75    0     190      80            91           193           371   \n",
       "1     56    1     165      64            81           174           401   \n",
       "2     54    0     172      95           138           163           386   \n",
       "3     55    0     175      94           100           202           380   \n",
       "4     75    0     190      80            88           181           360   \n",
       "5     13    0     169      51           100           167           321   \n",
       "6     40    1     160      52            77           129           377   \n",
       "7     49    1     162      54            78             0           376   \n",
       "8     44    0     168      56            84           118           354   \n",
       "9     50    1     167      67            89           130           383   \n",
       "10    62    0     170      72           102           135           401   \n",
       "11    45    1     165      86            77           143           373   \n",
       "12    54    1     172      58            78           155           382   \n",
       "13    30    0     170      73            91           180           355   \n",
       "14    44    1     160      88            77           158           399   \n",
       "15    47    1     150      48            75           132           350   \n",
       "16    47    0     171      59            82           145           347   \n",
       "17    46    1     158      58            70           120           353   \n",
       "18    73    0     165      63            91           154           392   \n",
       "19    57    1     166      72            82           181           399   \n",
       "20    28    1     160      58            83           251           383   \n",
       "21    45    0     169      67            90           122           336   \n",
       "22    36    1     153      75            71           132           364   \n",
       "23    57    1     165      59            75           157           406   \n",
       "24    40    1     153      55            82           140           388   \n",
       "25    44    0     169      80           109           128           382   \n",
       "26    34    0     170      73            94           186           373   \n",
       "27    31    1     160      54            95           161           407   \n",
       "28    56    1     164      65            90           164           420   \n",
       "29    51    1     160      83            96           147           400   \n",
       "..   ...  ...     ...     ...           ...           ...           ...   \n",
       "422   29    1     162      57            83           164           359   \n",
       "423   51    0     186      95            94           203           367   \n",
       "424    7    0     119      21           140           157           438   \n",
       "425   36    0     171      93            87           150           362   \n",
       "426   35    1     160      53            55           163           340   \n",
       "427   58    0     160      65           133           148           417   \n",
       "428   64    0     160      63            83             0           364   \n",
       "429    8    1     130      24            77           125           358   \n",
       "430   11    0     138      29           123           145           361   \n",
       "431   47    0     166      56            79           145           381   \n",
       "432   11    0     140      42            88           123           362   \n",
       "433   70    0     167      60            80           149           290   \n",
       "434   20    0     178      65            88           155           360   \n",
       "435   39    1     164      62            79           155           367   \n",
       "436   32    1     164      57            77           144           340   \n",
       "437   35    1     155      63            87           142           391   \n",
       "438   37    0     175      82            88           146           357   \n",
       "439   49    1     168      66            94           170           383   \n",
       "440   37    0     176      72            88           153           389   \n",
       "441   37    1     160      50            74           143           374   \n",
       "442   65    1     160      50            85           143           363   \n",
       "443   41    1     154      75            88           157           384   \n",
       "444   29    0     166      63            81           143           325   \n",
       "445   45    0     175      75            91           134           376   \n",
       "446   20    1     157      57            81           151           363   \n",
       "447   53    1     160      70            80           199           382   \n",
       "448   37    0     190      85           100           137           361   \n",
       "449   36    0     166      68           108           176           365   \n",
       "450   32    1     155      55            93           106           386   \n",
       "451   78    1     160      70            79           127           364   \n",
       "\n",
       "     T_interval  P_interval  QRS    ...    V6_Amp_JJ V6_Amp_Q V6_Amp_R  \\\n",
       "0           174         121  -16    ...         -0.3      0.0      9.0   \n",
       "1           149          39   25    ...         -0.5      0.0      8.5   \n",
       "2           185         102   96    ...          0.9      0.0      9.5   \n",
       "3           179         143   28    ...          0.1      0.0     12.2   \n",
       "4           177         103  -16    ...         -0.4      0.0     13.1   \n",
       "5           174          91  107    ...          0.0     -0.6     12.2   \n",
       "6           133          77   77    ...         -0.4      0.0      6.5   \n",
       "7           157          70   67    ...         -0.3      0.0      8.2   \n",
       "8           160          63   61    ...          0.1      0.0      7.0   \n",
       "9           156          73   85    ...         -0.5     -0.6     10.8   \n",
       "10          156          83   72    ...         -0.4     -0.5      9.0   \n",
       "11          150          65   12    ...          0.1      0.0      4.4   \n",
       "12          163          81  -24    ...         -0.2      0.0      6.3   \n",
       "13          157         104   68    ...         -0.6     -0.9     12.3   \n",
       "14          163          94   46    ...          0.1     -0.6     12.4   \n",
       "15          169          65   36    ...          0.0      0.0      7.7   \n",
       "16          169          61   77    ...         -0.4      0.0      9.4   \n",
       "17          122          52   57    ...         -0.6      0.0      6.6   \n",
       "18          175          83   73    ...         -0.5      0.0      5.7   \n",
       "19          158          79  -12    ...         -0.3      0.0      7.7   \n",
       "20          189         183   50    ...          0.0     -0.6      9.1   \n",
       "21          177          78   81    ...         -0.4     -0.6      8.3   \n",
       "22          169          82   62    ...         -0.1      0.0      8.9   \n",
       "23          143          92    4    ...          0.7      0.0      6.7   \n",
       "24          149          82   52    ...         -0.6      0.0     13.6   \n",
       "25          195          60  -34    ...         -0.7      0.0      6.9   \n",
       "26          224         125   90    ...         -0.3      0.0     15.3   \n",
       "27          168          83   10    ...          0.0      0.0     12.7   \n",
       "28          381          99   -8    ...         -0.4      0.0      5.4   \n",
       "29          301          82  -37    ...         -0.7      0.0      7.3   \n",
       "..          ...         ...  ...    ...          ...      ...      ...   \n",
       "422         154          69   64    ...         -0.4      0.0     14.1   \n",
       "423         171         106   -7    ...         -0.2      0.0      9.6   \n",
       "424         226          81  -40    ...          0.8      0.0     10.0   \n",
       "425         177          96   44    ...          0.2      0.0     10.3   \n",
       "426         162         102   40    ...          0.0      0.0      8.7   \n",
       "427         260          92 -158    ...          0.1     -0.4      6.4   \n",
       "428         120          90   29    ...          0.0      0.0      6.7   \n",
       "429         159          70   87    ...         -0.3      0.0     11.3   \n",
       "430         221          80  112    ...         -0.3     -3.4     19.6   \n",
       "431         173         101   52    ...         -0.6      0.0      8.5   \n",
       "432         228          81  -18    ...          0.1      0.0     17.1   \n",
       "433         128          93  -67    ...          0.1      0.0      2.7   \n",
       "434         163          71  -22    ...         -0.2     -0.5     10.2   \n",
       "435         153          95   50    ...         -0.1      0.0      9.7   \n",
       "436         148          82   27    ...          0.5     -0.6      9.9   \n",
       "437         137          88   66    ...         -0.6      0.0     10.7   \n",
       "438         179          72    1    ...         -0.4     -0.4     13.5   \n",
       "439         152         115   92    ...         -0.3      0.0      8.2   \n",
       "440         172          89   67    ...         -1.0     -0.9     16.6   \n",
       "441         146          75   68    ...          0.0      0.0     11.4   \n",
       "442         146          84  -40    ...         -0.1      0.0      6.6   \n",
       "443         132         112   65    ...         -0.4     -0.4     10.5   \n",
       "444         218          74   24    ...          0.1      0.0      7.8   \n",
       "445         160          83   91    ...         -0.4      0.0      7.1   \n",
       "446         166          80   43    ...          0.0      0.0      7.2   \n",
       "447         154         117  -37    ...          0.0      0.0      4.3   \n",
       "448         201          73   86    ...         -0.5      0.0     15.6   \n",
       "449         194         116  -85    ...          1.2      0.0     16.3   \n",
       "450         218          63   54    ...          0.2     -0.4     12.0   \n",
       "451         138          78   28    ...         -0.3      0.0     10.4   \n",
       "\n",
       "    V6_Amp_S  V6_Amp_R'  V6_Amp_S'  V6_Amp_P  V6_Amp_T  V6_QRSA  V6_QRSTA  \n",
       "0       -0.9        0.0          0       0.9       2.9     23.3      49.4  \n",
       "1        0.0        0.0          0       0.2       2.1     20.4      38.8  \n",
       "2       -2.4        0.0          0       0.3       3.4     12.3      49.0  \n",
       "3       -2.2        0.0          0       0.4       2.6     34.6      61.6  \n",
       "4       -3.6        0.0          0      -0.1       3.9     25.4      62.8  \n",
       "5       -2.8        0.0          0       0.9       2.2     13.5      31.1  \n",
       "6        0.0        0.0          0       0.4       1.0     14.3      20.5  \n",
       "7       -1.9        0.0          0       0.1       0.5     15.8      19.8  \n",
       "8       -1.3        0.0          0       0.6       2.1     12.5      30.9  \n",
       "9       -1.7        0.0          0       0.8       0.9     20.1      25.1  \n",
       "10      -2.0        0.0          0       0.8       0.9     12.3      19.3  \n",
       "11      -2.2        0.0          0       0.5       1.5      4.9      17.2  \n",
       "12      -2.1        0.0          0       0.8       0.5      8.8      12.1  \n",
       "13       0.0        0.0          0       0.4       2.1     28.5      48.6  \n",
       "14       0.0        0.0          0       0.3       1.7     39.2      54.1  \n",
       "15      -0.8        0.0          0       0.6       1.7     17.2      31.1  \n",
       "16      -1.7        0.0          0       0.6       2.3     19.5      41.1  \n",
       "17       0.0        0.0          0       0.3       0.7     17.1      20.8  \n",
       "18       0.0        0.0          0       0.4       0.5     18.2      22.4  \n",
       "19      -0.9        0.0          0       0.5       1.8     25.2      38.5  \n",
       "20      -1.4        0.0          0       0.6       3.3     17.1      54.7  \n",
       "21      -1.8        0.0          0       0.8       1.1     11.7      19.6  \n",
       "22      -1.0        0.0          0       0.5       1.7     19.7      34.3  \n",
       "23      -0.5        0.0          0       0.4       1.1     18.4      28.9  \n",
       "24       0.0        0.0          0       0.5       2.5     35.3      57.3  \n",
       "25       0.0        0.0          0       0.4       1.3     20.7      29.2  \n",
       "26      -1.1        0.0          0       0.6       2.6     44.0      68.4  \n",
       "27      -1.8        0.0          0       0.3       3.2     25.4      54.8  \n",
       "28       0.0        0.0          0       0.4      -1.4     17.2       3.0  \n",
       "29      -3.9        0.0          0       0.5      -1.1      3.6      -6.3  \n",
       "..       ...        ...        ...       ...       ...      ...       ...  \n",
       "422     -2.2        0.0          0       0.5       3.0     32.7      56.1  \n",
       "423     -3.5        0.0          0       1.0       1.6      9.4      23.4  \n",
       "424     -2.1        0.0          0       1.0       5.5     36.7     115.9  \n",
       "425     -0.8        0.0          0       0.6       3.0     24.1      52.9  \n",
       "426     -0.5        0.0          0       0.5       2.3     20.9      40.6  \n",
       "427     -3.5        0.0          0       0.4       0.8     -2.9       6.5  \n",
       "428     -0.4        0.0          0       0.3       0.4     23.7      26.4  \n",
       "429     -2.1        0.0          0       0.7       3.6     16.1      49.2  \n",
       "430     -4.2        0.0          0       0.2       1.8     12.2      25.1  \n",
       "431      0.0        0.0          0       0.6       1.2     20.4      29.0  \n",
       "432     -7.1        0.0          0       0.7       5.5     15.1      84.4  \n",
       "433     -5.4        0.0          0       0.3      -0.2     -7.1      -8.3  \n",
       "434      0.0        0.0          0       0.5       0.4     24.0      25.4  \n",
       "435     -0.7        0.0          0       0.8       1.3     24.1      33.7  \n",
       "436     -0.6        0.0          0       0.5       2.4     19.1      36.3  \n",
       "437      0.0        0.0          0       1.0       2.1     25.6      43.2  \n",
       "438     -1.2        0.0          0       0.5       0.6     30.1      35.0  \n",
       "439     -0.7        0.0          0       0.8       1.7     21.5      33.7  \n",
       "440     -3.4        0.0          0       0.7       1.8     24.9      41.4  \n",
       "441     -0.9        0.0          0       0.7       1.8     40.1      55.5  \n",
       "442     -6.1        0.0          0       0.5       0.5     -3.8       0.4  \n",
       "443     -2.5        0.0          0       0.5       1.4     17.8      29.5  \n",
       "444     -1.3        0.0          0       0.5       2.3     14.1      37.1  \n",
       "445     -2.4        0.0          0      -0.4       1.3      8.5      17.6  \n",
       "446     -0.7        0.0          0       0.5       2.3     17.6      39.2  \n",
       "447     -5.0        0.0          0       0.7       0.6     -4.4      -0.5  \n",
       "448     -1.6        0.0          0       0.4       2.4     38.0      62.4  \n",
       "449    -28.6        0.0          0       1.5       1.0    -44.2     -33.2  \n",
       "450     -0.7        0.0          0       0.5       2.4     25.0      46.6  \n",
       "451     -1.8        0.0          0       0.5       1.6     21.3      32.8  \n",
       "\n",
       "[452 rows x 278 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_X.drop(columns=['J'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing value\n",
    "We are imputing mean in place of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                 0\n",
       "Sex                 0\n",
       "Height              0\n",
       "Weight              0\n",
       "QRS_duration        0\n",
       "P-R_interval        0\n",
       "Q-T_interval        0\n",
       "T_interval          0\n",
       "P_interval          0\n",
       "QRS                 0\n",
       "T                   0\n",
       "P                   0\n",
       "QRST                0\n",
       "J                   0\n",
       "Heart_Rate          0\n",
       "DI_Q_wave           0\n",
       "DI_R_wave           0\n",
       "DI_S_wave           0\n",
       "DI_R'_wave          0\n",
       "DI_S'_wave          0\n",
       "DI_Intrinsic_def    0\n",
       "DI_Ragged_R         0\n",
       "DI_DD_R             0\n",
       "DI_Ragged_P         0\n",
       "DI_DD_P             0\n",
       "DI_Ragged_T         0\n",
       "DI_DD_T             0\n",
       "DII_Q_wave          0\n",
       "DII_R_wave          0\n",
       "DII_S_wave          0\n",
       "                   ..\n",
       "V4_Amp_JJ           0\n",
       "V4_Amp_Q            0\n",
       "V4_Amp_R            0\n",
       "V4_Amp_S            0\n",
       "V4_Amp_R'           0\n",
       "V4_Amp_S'           0\n",
       "V4_Amp_P            0\n",
       "V4_Amp_T            0\n",
       "V4_QRSA             0\n",
       "V4_QRSTA            0\n",
       "V5_Amp_JJ           0\n",
       "V5_Amp_Q            0\n",
       "V5_Amp_R            0\n",
       "V5_Amp_S            0\n",
       "V5_Amp_R'           0\n",
       "V5_Amp_S'           0\n",
       "V5_Amp_P            0\n",
       "V5_Amp_T            0\n",
       "V5_QRSA             0\n",
       "V5_QRSTA            0\n",
       "V6_Amp_JJ           0\n",
       "V6_Amp_Q            0\n",
       "V6_Amp_R            0\n",
       "V6_Amp_S            0\n",
       "V6_Amp_R'           0\n",
       "V6_Amp_S'           0\n",
       "V6_Amp_P            0\n",
       "V6_Amp_T            0\n",
       "V6_QRSA             0\n",
       "V6_QRSTA            0\n",
       "Length: 279, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "z=Imputer(missing_values=np.nan, strategy='mean', axis=1).fit_transform(Data_X)\n",
    "Data_X = pd.DataFrame(data=z,columns=Data_X.columns.values)\n",
    "Data_X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Good evaluation strategy\n",
    "As the dependent variabe is a categorical variable we will be using classification models. The best evaluation strategy for classification models is comparing the precision and recall. We know for a fact that R-sqaured and MSE scores are used extensively for checking the accuracy of a regression model where independent variable is a continous. However when we run classification models precision and recall are the best estimators of accuracy. Our main aim is to reduce the recall by improving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting down into both train and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (339, 279), shape of test (113, 279)\n"
     ]
    }
   ],
   "source": [
    "data_train_x, data_test_x, data_train_y, data_test_y = train_test_split(Data_X, Data_Y\n",
    "                                                                        , random_state=2)\n",
    "# Scaling the data (MIN MAX Scaling)\n",
    "print('Shape of train {}, shape of test {}'.format(data_train_x.shape, data_test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "As the variables are on different scale it will be helpful if we bring them all on the same scale. Scaling improves the performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#MinMax\n",
    "MinMax = MinMaxScaler(feature_range= (0,1))\n",
    "data_train_x = MinMax.fit_transform(data_train_x)\n",
    "data_test_x = MinMax.transform(data_test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling\n",
    "After taking care of the data we will be starting with the model creation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'weights': ['distance', 'uniform'], 'n_neighbors': range(1, 100)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## We are creating a grid for which all n_neighbors values are to be used for cross validation\n",
    "\n",
    "param_grid={'weights':['distance', 'uniform'], 'n_neighbors':range(1,100)}\n",
    "\n",
    "## Using Grid search for exhaustive searching\n",
    "\n",
    "grid_search = GridSearchCV( KNeighborsClassifier(),param_grid, cv = 10)\n",
    "grid_search.fit(data_train_x, data_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_Rsquare</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.973451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
       "0  KNN Classifier            1.0      0.504425        0.0  25.973451"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "train_Rsquare = grid_search.score(data_train_x, data_train_y)\n",
    "test_Rsquare = grid_search.score(data_test_x, data_test_y)\n",
    "train_MSE = mean_squared_error(data_train_y, grid_search.predict(data_train_x))\n",
    "test_MSE = mean_squared_error(data_test_y, grid_search.predict(data_test_x))\n",
    "output = output.append(pd.Series({'model':'KNN Classifier','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R-squared, MSE vs precision, Recall\n",
    "We know for a fact that R-sqaured and MSE scores are used extensively for checking the accuracy of a regression model where independent variable is a continous. However when we run classification models precision and recall are the best estimators of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='distance')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.96      0.67        57\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.00      0.00      0.00         6\n",
      "          4       1.00      0.25      0.40         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       1.00      0.11      0.20         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.37      0.50      0.37       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
    "           weights='distance')\n",
    "knn.fit(data_train_x, data_train_y)\n",
    "pred = knn.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Evaluation\n",
    "In the whole process of model creation, our aim will be to achieve maximum Precision (no false positive) and maximum Recall (no false negative) there needs to be an absence of type I and II errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "grid_search_log = GridSearchCV(LogisticRegression(penalty='l2'), param_grid, cv=5)\n",
    "grid_search_log.fit(data_train_x, data_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_Rsquare</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.973451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.823009</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>9.351032</td>\n",
       "      <td>17.991150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
       "0       KNN Classifier       1.000000      0.504425   0.000000  25.973451\n",
       "1  Logistic Regression       0.823009      0.699115   9.351032  17.991150"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "train_Rsquare = grid_search_log.score(data_train_x, data_train_y)\n",
    "test_Rsquare = grid_search_log.score(data_test_x, data_test_y)\n",
    "train_MSE = mean_squared_error(data_train_y, grid_search_log.predict(data_train_x))\n",
    "test_MSE = mean_squared_error(data_test_y, grid_search_log.predict(data_test_x))\n",
    "output = output.append(pd.Series({'model':'Logistic Regression','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(grid_search_log.cv_results_)\n",
    "print(grid_search_log.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.96      0.80        57\n",
      "          2       0.55      0.43      0.48        14\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       0.75      0.75      0.75         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.25      0.40         4\n",
      "         10       0.88      0.78      0.82         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       1.00      0.17      0.29         6\n",
      "\n",
      "avg / total       0.65      0.70      0.64       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "log.fit(data_train_x, data_train_y)\n",
    "pred = log.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Supprt Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter': [1000, 10000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'max_iter':[1000,10000] }\n",
    "\n",
    "grid_search_SVC = GridSearchCV(LinearSVC(random_state=0), param_grid, cv=5)\n",
    "grid_search_SVC.fit(data_train_x, data_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_Rsquare</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.973451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.823009</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>9.351032</td>\n",
       "      <td>17.991150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>10.351032</td>\n",
       "      <td>17.548673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
       "0       KNN Classifier       1.000000      0.504425   0.000000  25.973451\n",
       "1  Logistic Regression       0.823009      0.699115   9.351032  17.991150\n",
       "2           Linear SVC       0.828909      0.699115  10.351032  17.548673"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Rsquare = grid_search_SVC.score(data_train_x, data_train_y)\n",
    "test_Rsquare = grid_search_SVC.score(data_test_x, data_test_y)\n",
    "train_MSE = mean_squared_error(data_train_y, grid_search_SVC.predict(data_train_x))\n",
    "test_MSE = mean_squared_error(data_test_y, grid_search_SVC.predict(data_test_x))\n",
    "output = output.append(pd.Series({'model':'Linear SVC','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(grid_search_SVC.cv_results_)\n",
    "print(grid_search_SVC.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.95      0.79        57\n",
      "          2       0.60      0.43      0.50        14\n",
      "          3       0.86      1.00      0.92         6\n",
      "          4       1.00      0.75      0.86         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.67      0.50      0.57         4\n",
      "         10       0.78      0.78      0.78         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       1.00      0.17      0.29         6\n",
      "\n",
      "avg / total       0.64      0.70      0.64       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "linearsvc = LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
    "     verbose=0)\n",
    "linearsvc.fit(data_train_x, data_train_y)\n",
    "pred = linearsvc.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kerenilzed Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'gamma': [0.001, 0.01, 0.1, 0.5, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C':[0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'gamma':[0.001, 0.01, 0.1, 0.5, 1, 10]}\n",
    "\n",
    "grid_search_KSVC = GridSearchCV(SVC(kernel = 'rbf'), param_grid, cv=5)\n",
    "grid_search_KSVC.fit(data_train_x, data_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_Rsquare</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.973451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.823009</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>9.351032</td>\n",
       "      <td>17.991150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>10.351032</td>\n",
       "      <td>17.548673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kernel SVC</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>6.628319</td>\n",
       "      <td>23.070796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
       "0       KNN Classifier       1.000000      0.504425   0.000000  25.973451\n",
       "1  Logistic Regression       0.823009      0.699115   9.351032  17.991150\n",
       "2           Linear SVC       0.828909      0.699115  10.351032  17.548673\n",
       "3           Kernel SVC       0.893805      0.707965   6.628319  23.070796"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Rsquare = grid_search_KSVC.score(data_train_x, data_train_y)\n",
    "test_Rsquare = grid_search_KSVC.score(data_test_x, data_test_y)\n",
    "train_MSE = mean_squared_error(data_train_y, grid_search_KSVC.predict(data_train_x))\n",
    "test_MSE = mean_squared_error(data_test_y, grid_search_KSVC.predict(data_test_x))\n",
    "output = output.append(pd.Series({'model':'Kernel SVC','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(grid_search_KSVC.cv_results_)\n",
    "print(grid_search_KSVC.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.91      0.78        57\n",
      "          2       0.80      0.57      0.67        14\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       0.80      1.00      0.89         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.75      0.75      0.75         4\n",
      "         10       1.00      0.67      0.80         9\n",
      "         15       1.00      0.50      0.67         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.65      0.71      0.66       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "svc.fit(data_train_x, data_train_y)\n",
    "pred = svc.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': [None, 'auto', 'log2'], 'max_depth': [5, 10, 15, 20, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = {'max_features':[None,'auto', 'log2'], 'max_depth':[5,10,15,20,50]}\n",
    "\n",
    "grid_search_DT = GridSearchCV(DecisionTreeClassifier(random_state = 10), param_grid, cv=5)\n",
    "grid_search_DT.fit(data_train_x, data_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_Rsquare</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.973451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.823009</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>9.351032</td>\n",
       "      <td>17.991150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>10.351032</td>\n",
       "      <td>17.548673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kernel SVC</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>6.628319</td>\n",
       "      <td>23.070796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.958702</td>\n",
       "      <td>0.663717</td>\n",
       "      <td>4.126844</td>\n",
       "      <td>21.292035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
       "0            KNN Classifier       1.000000      0.504425   0.000000  25.973451\n",
       "1       Logistic Regression       0.823009      0.699115   9.351032  17.991150\n",
       "2                Linear SVC       0.828909      0.699115  10.351032  17.548673\n",
       "3                Kernel SVC       0.893805      0.707965   6.628319  23.070796\n",
       "4  Decision Tree Classifier       0.958702      0.663717   4.126844  21.292035"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Rsquare = grid_search_DT.score(data_train_x, data_train_y)\n",
    "test_Rsquare = grid_search_DT.score(data_test_x, data_test_y)\n",
    "train_MSE = mean_squared_error(data_train_y, grid_search_DT.predict(data_train_x))\n",
    "test_MSE = mean_squared_error(data_test_y, grid_search_DT.predict(data_test_x))\n",
    "output = output.append(pd.Series({'model':'Decision Tree Classifier','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(grid_search_DT.cv_results_)\n",
    "print(grid_search_DT.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.88      0.81        57\n",
      "          2       0.78      0.50      0.61        14\n",
      "          3       0.67      0.67      0.67         6\n",
      "          4       0.25      0.25      0.25         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.62      0.83      0.71         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.50      0.78      0.61         9\n",
      "         14       0.00      0.00      0.00         0\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.50      0.17      0.25         6\n",
      "\n",
      "avg / total       0.62      0.66      0.63       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
    "            splitter='best')\n",
    "dt.fit(data_train_x, data_train_y)\n",
    "pred = dt.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=30, n_jobs=-1,\n",
       "          param_distributions={'max_depth': [3, 5], 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000111812B4C50>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000111812B4D68>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001118145C940>, 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "#Tuning ridge on new dataset\n",
    "param_grid = {\"max_depth\": [3, 5],\n",
    "              \"max_features\": sp_randint(1, 40),\n",
    "              \"min_samples_split\": sp_randint(2, 30),\n",
    "              \"min_samples_leaf\": sp_randint(1, 20),\n",
    "              \"bootstrap\": [True, False]}\n",
    "grid_search_RF = RandomizedSearchCV(RandomForestClassifier(n_estimators=1000), param_distributions=param_grid,\n",
    "                                   n_iter=30, random_state=0,n_jobs=-1)\n",
    "grid_search_RF.fit(data_train_x, data_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_Rsquare</th>\n",
       "      <th>test_Rsquare</th>\n",
       "      <th>train_MSE</th>\n",
       "      <th>test_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.973451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.823009</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>9.351032</td>\n",
       "      <td>17.991150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>10.351032</td>\n",
       "      <td>17.548673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kernel SVC</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>6.628319</td>\n",
       "      <td>23.070796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.958702</td>\n",
       "      <td>0.663717</td>\n",
       "      <td>4.126844</td>\n",
       "      <td>21.292035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.755162</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>17.731563</td>\n",
       "      <td>22.663717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  train_Rsquare  test_Rsquare  train_MSE   test_MSE\n",
       "0            KNN Classifier       1.000000      0.504425   0.000000  25.973451\n",
       "1       Logistic Regression       0.823009      0.699115   9.351032  17.991150\n",
       "2                Linear SVC       0.828909      0.699115  10.351032  17.548673\n",
       "3                Kernel SVC       0.893805      0.707965   6.628319  23.070796\n",
       "4  Decision Tree Classifier       0.958702      0.663717   4.126844  21.292035\n",
       "5  Random Forest Classifier       0.755162      0.637168  17.731563  22.663717"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Rsquare = grid_search_RF.score(data_train_x, data_train_y)\n",
    "test_Rsquare = grid_search_RF.score(data_test_x, data_test_y)\n",
    "train_MSE = mean_squared_error(data_train_y, grid_search_RF.predict(data_train_x))\n",
    "test_MSE = mean_squared_error(data_test_y, grid_search_RF.predict(data_test_x))\n",
    "output = output.append(pd.Series({'model':'Random Forest Classifier','train_Rsquare':train_Rsquare, 'test_Rsquare':test_Rsquare, 'train_MSE':train_MSE,'test_MSE':test_MSE}),ignore_index=True )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=36, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=7, min_samples_split=25,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(grid_search_RF.cv_results_)\n",
    "print(grid_search_RF.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.98      0.78        57\n",
      "          2       0.58      0.50      0.54        14\n",
      "          3       1.00      0.50      0.67         6\n",
      "          4       0.00      0.00      0.00         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.73      0.89      0.80         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.51      0.65      0.56       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=5, max_features=36, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=7, min_samples_split=25,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "rf.fit(data_train_x, data_train_y)\n",
    "pred = rf.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bagging\n",
    "We will be using bagging to improve our earlier model with best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   KNN with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.96      0.67        57\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.00      0.00      0.00         6\n",
      "          4       1.00      0.25      0.40         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       1.00      0.11      0.20         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.37      0.50      0.37       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "KNN_bagging = BaggingClassifier(knn, n_estimators = 100, bootstrap = True)\n",
    "KNN_bagging.fit(data_train_x,data_train_y)\n",
    "pred = KNN_bagging.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.98      0.76        57\n",
      "          2       0.44      0.29      0.35        14\n",
      "          3       1.00      0.83      0.91         6\n",
      "          4       1.00      0.50      0.67         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.67      0.44      0.53         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.51      0.63      0.54       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "log_bagging = BaggingClassifier(log , n_estimators = 100, max_features = 200 ,bootstrap = True, oob_score = True)\n",
    "log_bagging.fit(data_train_x, data_train_y)\n",
    "pred = log_bagging.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.96      0.78        57\n",
      "          2       0.57      0.29      0.38        14\n",
      "          3       0.86      1.00      0.92         6\n",
      "          4       1.00      0.75      0.86         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.67      0.50      0.57         4\n",
      "         10       0.75      0.67      0.71         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.57      0.67      0.60       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "linearsvc_bagging = BaggingClassifier(linearsvc , n_estimators = 100, max_features = 200 ,\n",
    "                                      bootstrap = True, oob_score = True)\n",
    "linearsvc_bagging.fit(data_train_x, data_train_y)\n",
    "pred = linearsvc_bagging.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernalized SVC with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.96      0.79        57\n",
      "          2       0.70      0.50      0.58        14\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       0.80      1.00      0.89         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.75      0.75      0.75         4\n",
      "         10       1.00      0.56      0.71         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.61      0.71      0.64       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svc_bagging = BaggingClassifier(svc , n_estimators = 100, max_features = 200 ,\n",
    "                                      bootstrap = True, oob_score = True)\n",
    "svc_bagging.fit(data_train_x, data_train_y)\n",
    "pred = svc_bagging.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.95      0.82        57\n",
      "          2       0.62      0.57      0.59        14\n",
      "          3       1.00      0.50      0.67         6\n",
      "          4       1.00      0.25      0.40         4\n",
      "          5       1.00      0.25      0.40         4\n",
      "          6       0.83      0.83      0.83         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.75      0.86         4\n",
      "         10       0.67      0.89      0.76         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.70      0.73      0.69       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dt_bagging = BaggingClassifier(dt , n_estimators = 100, max_features = 200 ,\n",
    "                                      bootstrap = True, oob_score = True)\n",
    "dt_bagging.fit(data_train_x, data_train_y)\n",
    "pred = dt_bagging.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest with bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      1.00      0.77        57\n",
      "          2       0.60      0.43      0.50        14\n",
      "          3       1.00      0.33      0.50         6\n",
      "          4       0.00      0.00      0.00         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.80      0.89      0.84         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.51      0.65      0.54       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rf_bagging = BaggingClassifier(rf , n_estimators = 100, max_features = 200 ,\n",
    "                                      bootstrap = True, oob_score = True)\n",
    "rf_bagging.fit(data_train_x, data_train_y)\n",
    "pred = rf_bagging.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "The main idea behind using boosting is to convert weak learners "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada boosting with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      1.00      0.70        57\n",
      "          2       0.67      0.14      0.24        14\n",
      "          3       1.00      0.17      0.29         6\n",
      "          4       0.00      0.00      0.00         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.67      0.22      0.33         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.46      0.55      0.43       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
    "adaboost_log = GridSearchCV(AdaBoostClassifier(base_estimator = log,random_state = 0), param_grid, cv=5,return_train_score=True)\n",
    "adaboost_log.fit(data_train_x, data_train_y)\n",
    "\n",
    "pred = adaboost_log.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada boosting with Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.95      0.79        57\n",
      "          2       0.60      0.43      0.50        14\n",
      "          3       0.86      1.00      0.92         6\n",
      "          4       1.00      0.75      0.86         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.67      0.50      0.57         4\n",
      "         10       0.78      0.78      0.78         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       1.00      0.17      0.29         6\n",
      "\n",
      "avg / total       0.64      0.70      0.64       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
    "adaboost_svc = GridSearchCV(AdaBoostClassifier(base_estimator = linearsvc,random_state = 0, algorithm='SAMME'),\n",
    "                            param_grid, cv=5,return_train_score=True)\n",
    "adaboost_svc.fit(data_train_x, data_train_y)\n",
    "\n",
    "pred = adaboost_svc.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada boosting with Kernalized SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      1.00      0.67        57\n",
      "          2       0.00      0.00      0.00        14\n",
      "          3       0.00      0.00      0.00         6\n",
      "          4       0.00      0.00      0.00         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         4\n",
      "         10       0.00      0.00      0.00         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.25      0.50      0.34       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
    "adaboost_ksvc = GridSearchCV(AdaBoostClassifier(base_estimator = svc,random_state = 0, algorithm='SAMME'),\n",
    "                            param_grid, cv=5,return_train_score=True)\n",
    "adaboost_ksvc.fit(data_train_x, data_train_y)\n",
    "\n",
    "pred = adaboost_ksvc.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boosting with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.82      0.78        57\n",
      "          2       0.50      0.50      0.50        14\n",
      "          3       0.00      0.00      0.00         6\n",
      "          4       0.50      0.75      0.60         4\n",
      "          5       1.00      0.25      0.40         4\n",
      "          6       0.67      0.67      0.67         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.50      0.67         4\n",
      "         10       0.44      0.78      0.56         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.60      0.63      0.60       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "param_grid = {'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
    "adaboost_dt = GridSearchCV(AdaBoostClassifier(base_estimator = dt,random_state = 0),\n",
    "                            param_grid, cv=5,return_train_score=True)\n",
    "adaboost_dt.fit(data_train_x, data_train_y)\n",
    "\n",
    "pred = adaboost_dt.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boosting with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.98      0.79        57\n",
      "          2       0.55      0.43      0.48        14\n",
      "          3       1.00      0.50      0.67         6\n",
      "          4       1.00      0.25      0.40         4\n",
      "          5       0.00      0.00      0.00         4\n",
      "          6       0.00      0.00      0.00         6\n",
      "          8       0.00      0.00      0.00         1\n",
      "          9       1.00      0.50      0.67         4\n",
      "         10       0.64      0.78      0.70         9\n",
      "         15       0.00      0.00      0.00         2\n",
      "         16       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.57      0.66      0.59       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=10, n_estimators= 500)\n",
    "\n",
    "param_grid = {'max_features':['auto', 'log2'], 'learning_rate' : [0.01,0.1], 'max_depth':[5,10,15,30,50]}\n",
    "\n",
    "grid_search_gb = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search_gb.fit(data_train_x, data_train_y)\n",
    "pred = grid_search_gb.predict(data_test_x)\n",
    "print(classification_report(data_test_y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing bagging and boosting models with previous one's\n",
    "When we compare the precision and recall of earlier model with models with baaging and boosting we see that the new models accuracy has dropped. Bagging and boosting are used to lower the bias of the model, When we apply boost we introduce the risk of overfitting. Overfitting ulitmately lowers the accuracy estimated by cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PCA\n",
    "We will be using principal component analysis for data reduction. We have 278 variables which is increasing the complexity of the models. PCA reduces the complexity of the model by only considering the important variables and thus reducing the overall data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(0.95)\n",
    "pca.fit(Data_X)\n",
    "Data_X_PCA = pca.transform(Data_X)\n",
    "\n",
    "data_train_x_pca, data_test_x_pca, data_train_y_pca, data_test_y_pca = train_test_split(Data_X_PCA, Data_Y, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking results of 2 scalars\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#MinMax\n",
    "MinMax = MinMaxScaler(feature_range= (0,1))\n",
    "data_train_x_pca = MinMax.fit_transform(data_train_x_pca)\n",
    "data_test_x_pca = MinMax.transform(data_test_x_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5368731563421829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {'weights':['distance', 'uniform'], 'n_neighbors':range(3,100)}\n",
    "\n",
    "grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5,return_train_score=True)\n",
    "grid_search_knn.fit(data_train_x_pca, data_train_y_pca)\n",
    "pd.DataFrame(grid_search_knn.cv_results_)\n",
    "print(grid_search_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='distance')\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_knn.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.93      0.79        72\n",
      "          2       0.33      0.10      0.15        10\n",
      "          3       0.00      0.00      0.00         5\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         5\n",
      "         10       0.80      0.44      0.57         9\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.53      0.64      0.56       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "knn_pca = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='distance')\n",
    "knn_pca.fit(data_train_x_pca, data_train_y_pca)\n",
    "pred = knn_pca.predict(data_test_x_pca)\n",
    "print(classification_report(data_test_y_pca,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C': range(1,100) }\n",
    "\n",
    "grid_search_log = GridSearchCV(LogisticRegression(penalty='l1'), param_grid, cv=5,return_train_score=True)\n",
    "grid_search_log.fit(data_train_x_pca, data_train_y_pca)\n",
    "pd.DataFrame(grid_search_log.cv_results_)\n",
    "print(grid_search_log.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_log.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.93      0.86        72\n",
      "          2       0.57      0.40      0.47        10\n",
      "          3       0.83      1.00      0.91         5\n",
      "          4       0.50      1.00      0.67         2\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         5\n",
      "         10       0.88      0.78      0.82         9\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.68      0.75      0.71       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "logistic_pca = LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "logistic_pca.fit(data_train_x_pca, data_train_y_pca)\n",
    "pred = logistic_pca.predict(data_test_x_pca)\n",
    "print(classification_report(data_test_y_pca,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=100,\n",
      "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "param_grid = {'C': [0.0001,0.001,0.01,0.1,2,3,4,5,6,7,8,9], 'max_iter':[100,1000,10000] }\n",
    "\n",
    "grid_search_linearsvc = GridSearchCV(LinearSVC(random_state=0), param_grid, cv=5,return_train_score=True)\n",
    "grid_search_linearsvc.fit(data_train_x_pca, data_train_y_pca)\n",
    "pd.DataFrame(grid_search_linearsvc.cv_results_)\n",
    "print(grid_search_linearsvc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.92      0.86        72\n",
      "          2       0.57      0.40      0.47        10\n",
      "          3       0.83      1.00      0.91         5\n",
      "          4       0.50      1.00      0.67         2\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         5\n",
      "         10       0.75      0.67      0.71         9\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.68      0.73      0.70       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "linearsvc = LinearSVC(C=2, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=100,\n",
    "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
    "     verbose=0)\n",
    "linearsvc.fit(data_train_x_pca, data_train_y_pca)\n",
    "pred = linearsvc.predict(data_test_x_pca)\n",
    "print(classification_report(data_test_y_pca,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernalized SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C':[0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000], 'gamma':[0.001, 0.01, 0.1, 0.5, 1, 10]}\n",
    "\n",
    "grid_search_svc = GridSearchCV(SVC(kernel = 'rbf'), param_grid, cv=5,return_train_score=True)\n",
    "grid_search_svc.fit(data_train_x_pca, data_train_y_pca)\n",
    "pd.DataFrame(grid_search_svc.cv_results_)\n",
    "print(grid_search_svc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.97      0.86        72\n",
      "          2       0.50      0.30      0.37        10\n",
      "          3       0.80      0.80      0.80         5\n",
      "          4       0.67      1.00      0.80         2\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         5\n",
      "         10       0.75      0.67      0.71         9\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.65      0.75      0.69       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "svc.fit(data_train_x_pca, data_train_y_pca)\n",
    "pred = svc.predict(data_test_x_pca)\n",
    "print(classification_report(data_test_y_pca,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "            max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = {'max_features':['auto', 'log2'], 'max_depth':[3,5,7,9,10,11,13,15,20,50]}\n",
    "\n",
    "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state = 0), param_grid, cv=5,return_train_score=True)\n",
    "grid_search_dt.fit(data_train_x_pca, data_train_y_pca)\n",
    "pd.DataFrame(grid_search_dt.cv_results_)\n",
    "print(grid_search_dt.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.85      0.76        72\n",
      "          2       0.20      0.20      0.20        10\n",
      "          3       0.67      0.40      0.50         5\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         5\n",
      "         10       0.18      0.22      0.20         9\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.50      0.59      0.54       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dt_pca = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
    "            splitter='best')\n",
    "dt_pca.fit(data_train_x_pca, data_train_y_pca)\n",
    "pred = dt_pca.predict(data_test_x_pca)\n",
    "print(classification_report(data_test_y_pca,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=9, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "#Tuning ridge on new dataset\n",
    "param_grid = {\"max_depth\": sp_randint(3, 9),\n",
    "              \"max_features\": sp_randint(1, 10),\n",
    "              \"min_samples_split\": sp_randint(2, 20),\n",
    "              \"min_samples_leaf\": sp_randint(1, 20),\n",
    "              \"bootstrap\": [True, False]}\n",
    "random_search_rf = RandomizedSearchCV(RandomForestClassifier(n_estimators=1000), param_distributions=param_grid,\n",
    "                                   n_iter=30, random_state=0,n_jobs=-1, cv= 5,return_train_score=True)\n",
    "random_search_rf.fit(data_train_x_pca, data_train_y_pca)\n",
    "pd.DataFrame(random_search_rf.cv_results_)\n",
    "print(random_search_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.92      0.83        72\n",
      "          2       0.50      0.50      0.50        10\n",
      "          3       0.75      0.60      0.67         5\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         5\n",
      "         10       0.36      0.44      0.40         9\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.58      0.69      0.63       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rf_pca = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=5, max_features=9, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=2, min_samples_split=3,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "rf_pca.fit(data_train_x_pca, data_train_y_pca)\n",
    "pred = rf_pca.predict(data_test_x_pca)\n",
    "print(classification_report(data_test_y_pca,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.01, loss='deviance', max_depth=9,\n",
      "              max_features=6, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=7, min_samples_split=19,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"max_depth\": sp_randint(5,30),\n",
    "              \"max_features\": sp_randint(1, 35),\n",
    "              \"min_samples_split\": sp_randint(2, 40),\n",
    "              \"min_samples_leaf\": sp_randint(1, 30),\n",
    "             'learning_rate': [0.01,0.001,0.1]}\n",
    "random_search_gb = RandomizedSearchCV(GradientBoostingClassifier(n_estimators=1000), param_distributions=param_grid,\n",
    "                                   n_iter=30, random_state=0,n_jobs=-1,cv= 5,return_train_score=True)\n",
    "random_search_gb.fit(data_train_x_pca, data_train_y_pca)\n",
    "pd.DataFrame(random_search_gb.cv_results_)\n",
    "print(random_search_gb.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.93      0.85        72\n",
      "          2       0.67      0.60      0.63        10\n",
      "          3       0.83      1.00      0.91         5\n",
      "          4       0.50      0.50      0.50         2\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.50      0.20      0.29         5\n",
      "         10       0.62      0.56      0.59         9\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.68      0.75      0.71       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "gbc_pca = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.01, loss='deviance', max_depth=9,\n",
    "              max_features=6, max_leaf_nodes=None,\n",
    "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "              min_samples_leaf=7, min_samples_split=19,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
    "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "gbc_pca.fit(data_train_x_pca, data_train_y_pca)\n",
    "pred = gbc_pca.predict(data_test_x_pca)\n",
    "print(classification_report(data_test_y_pca,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA boosting with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1,\n",
      "          n_estimators=1000, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate' :[0.0001,0.001,0.01,0.1,1,1.2,2] ,\n",
    "              \"algorithm\":['SAMME', 'SAMME.R']}\n",
    "random_search_ada = RandomizedSearchCV(AdaBoostClassifier(n_estimators = 1000), param_distributions=param_grid,\n",
    "                                   n_iter=10, random_state=0,n_jobs=-1,cv= 5,return_train_score=True)\n",
    "random_search_ada.fit(data_train_x_pca, data_train_y_pca)\n",
    "pd.DataFrame(random_search_ada.cv_results_)\n",
    "print(random_search_ada.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.85      0.78        72\n",
      "          2       0.00      0.00      0.00        10\n",
      "          3       0.67      0.40      0.50         5\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.50      0.20      0.29         5\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.31      0.44      0.36         9\n",
      "         14       0.00      0.00      0.00         1\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.54      0.60      0.56       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\harsh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "ada_pca = AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1,\n",
    "          n_estimators=1000, random_state=None)\n",
    "ada_pca.fit(data_train_x_pca, data_train_y_pca)\n",
    "pred = ada_pca.predict(data_test_x_pca)\n",
    "print(classification_report(data_test_y_pca,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation after PCA\n",
    "The models started performing better after we applied PCA on the original data. The reason behind this is, PCA reduces the complexity of the data. It creates components based on giving importance to variables with large variance and also the components which it creates are non collinear in nature which means it takes care of collinearity in large data set. PCA also improves the overall execution time and quality of the models and it is very beneficial when we are working with huge amount of variables.\n",
    "The Best model according to the precision and recall score is Kernalized SVM with PCA having accuracy of 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
